{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os \n",
    "import json\n",
    "import holidays\n",
    "import folium\n",
    "import matplotlib.image as mpimg\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "import datetime as dt\n",
    "from ipywidgets import interact, widgets\n",
    "from scipy.stats import pearsonr\n",
    "from folium.plugins import MarkerCluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks = os.getcwd()\n",
    "df_main = pd.read_csv(notebooks + '/../data/processed/sf_crime_cleaned.csv')\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(notebooks + '/../data/processed/sf_incident_dtypes.json', 'r') as f:\n",
    "    data_types = json.load(f)\n",
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.astype(data_types)\n",
    "df_main.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check how crime rate changes by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['date_time'] = pd.to_datetime(df_main['incident_date'].dt.strftime(\"%Y-%m-%d\") + \" \" +df_main['incident_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.set_index('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ =sns.barplot(df_main.incident_year.value_counts())\n",
    "plt.title(\"Incident count for Years (2018-2024)\")\n",
    "_.annotate(\n",
    "    '',  # Text for annotation\n",
    "    xy=(0, 97000),  # Point to annotate\n",
    "    xytext=(5, 86000),  # Location for the text\n",
    "    arrowprops=dict(color='green', arrowstyle='<-'), \n",
    "    color='red'# Arrow properties\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  We can see the Covid-19 lockdown effect on year 2020 - 2021.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# since we know covid-19 had great impact on crime on 2020 and at the begining of 2021. What we see there is decrease on total crimes by each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "df_cat = pd.DataFrame(df_main['category'].value_counts().sort_values(ascending=False))\n",
    "df_cat = df_cat.reset_index() \n",
    "df_cat.columns = ['category', 'count'] \n",
    "\n",
    "\n",
    "sns.barplot(x='category', y='count', data=df_cat, order=df_cat['category'])\n",
    "plt.xticks(rotation=90)  \n",
    "plt.title('Total counts for each Type of Crime From 2018 to 2024')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearly Larceny Theft is number one crime in San Francisco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets go with top 5 crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_cat = df_main.value_counts(subset='category').sort_values(ascending=False).iloc[:5].reset_index()['category'].tolist()\n",
    "top5_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for cat in top5_cat:\n",
    "    sns.barplot(df_main[df_main.category == cat].incident_year.value_counts(), label=cat)\n",
    "plt.legend()\n",
    "plt.title('Yearly Incident Counts for Top 5 Crime Categories')\n",
    "plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It seems that while a significant number of assaults were reported before 2020, there were fewer reports after 2020. Conversely, motor vehicle thefts increased after 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the average 'Larceny Theft' in a day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = df_main.groupby(['incident_date', 'category']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "daily_avg = daily_counts.groupby('category')['count'].mean().reset_index(name='daily_average')\n",
    "daily_avg= daily_avg.sort_values('daily_average', ascending=False)\n",
    "daily_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the distributrion from Monday to Sunday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday = df_main.incident_date.unique().strftime(\"%A\")\n",
    "days, counts = np.unique(df_weekday, return_counts=True)\n",
    "df_days = pd.DataFrame({\"incident_day\":days, \"day_count\":counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_cat = df_main.groupby('incident_day')['category'].value_counts().reset_index()\n",
    "df_merged =df_day_cat.merge(df_days, on=\"incident_day\", how='left')\n",
    "df_merged['daily_avg'] = df_merged['count'] / df_merged['day_count'] \n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Daily Average of 5 Top Crime\")\n",
    "for cat in top5_cat:\n",
    "    sns.barplot(x='incident_day', y='daily_avg', data=df_merged[df_merged.category == cat], label=cat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily average shows that more crime is happening on fridays and saturdays, we will check that it is statisticly significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start with splitting our data to weekend and weekdays\n",
    "df_weekdays = df_main[~df_main.incident_date.dt.strftime('%A').isin(['Friday', 'Saturday'])][['incident_date', 'neighborhood',\t'latitude',\t'longitude', 'category', 'subcategory']]\n",
    "df_weekends =  df_main[df_main.incident_date.dt.strftime('%A').isin(['Friday', 'Saturday'])][['incident_date', 'neighborhood',\t'latitude',\t'longitude', 'category', 'subcategory']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekdays = df_main[~df_main.incident_date.dt.strftime('%A').isin(['Friday', 'Saturday'])][['incident_date', 'neighborhood',\t'latitude',\t'longitude', 'category', 'subcategory']]\n",
    "df_weekends =  df_main[df_main.incident_date.dt.strftime('%A').isin(['Friday', 'Saturday'])][['incident_date', 'neighborhood',\t'latitude',\t'longitude', 'category', 'subcategory']]\n",
    "prob_weekend = (df_weekends.size/2)/df_main.size\n",
    "prob_weekday = (df_weekdays.size/5)/df_main.size \n",
    "print(f'Weekend: {prob_weekend}')\n",
    "print(f'Weekday: {prob_weekday}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When we compare weekend to weekdays we see slightly higher probability of crime on weekends. Is that statisticly significant? \n",
    "## Let's find out ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Hypothessis will say there is no difference between weekdays and  weekends.\n",
    "# I will run permutation test to test that hypothesis.\n",
    "#I will take 100 samples from main data 1000 times \n",
    "np.random.seed = 42\n",
    "\n",
    "# calculate the total incident report for each day\n",
    "df_daily = df_main.groupby('incident_date').size().reset_index()\n",
    "df_daily.columns = ['incident_date', 'incident_count']\n",
    "\n",
    "df_daily['is_weekend'] =df_daily.incident_date.dt.strftime('%A').isin(['Friday','Saturday'])\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "daily_mean_sample_list = []\n",
    "for i in range(1000):\n",
    "    daily_mean_sample_list.append(df_daily.sample(100)['incident_count'].mean())\n",
    "\n",
    "plt.hist(daily_mean_sample_list, bins=30, color='orange', alpha=0.7)\n",
    "plt.axvline(x=df_daily['incident_count'].mean(), color='blue', linestyle='--', label='Daily Average')\n",
    "percentiles = np.percentile(daily_mean_sample_list, [2.5, 97.5])\n",
    "plt.axvline(x=percentiles[0], color='red', linestyle='--', label='2.5th Percentile')\n",
    "plt.axvline(x=percentiles[1], color='red', linestyle='--', label='97.5th Percentile')\n",
    "plt.axvline(x=(observed_weekend_average:=df_daily[df_daily['is_weekend']]['incident_count'].mean()), color='green', linestyle='-', label='Weekend Average')\n",
    "plt.legend()\n",
    "plt.xlabel('Incident Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Permutation Test - Incident Count Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having weekend average from the null hypothessis case is a very unlikely. For that reason we can reject the null hypothessis.\n",
    "## Let's calculate the p-value. (threshold is 0.05 selected) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.mean(np.array(daily_mean_sample_list) >= observed_weekend_average)\n",
    "print(f\"p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets see the daily total crime counts for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(20,10))\n",
    "ax = ax.flatten()\n",
    "df_daily['year'] = df_daily.incident_date.dt.year\n",
    "for i, year in enumerate(range(2018, 2024)):\n",
    "    data=df_daily.query(\"year==@year\")\n",
    "    ax[i].scatter(data['incident_date'], data['incident_count'], c=data['incident_count'], cmap='viridis_r')\n",
    "    ax[i].set_title(f\"Daily incident counts for {year}\")\n",
    "    ax[i].set_xlabel(\"Date\")\n",
    "    if not i%3:\n",
    "        ax[i].set_ylabel(\"Total Crime Amount\")\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Year's Day consistently has significantly higher crime than the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When  I look on year 2019, 2022 and 2023 there are one day has more crime than any other days.  Let's find out what are those days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_daily.query('(year == 2019) & (incident_count > 400)')['incident_date'].dt.strftime(\"%y-%m-%d\").iloc[0], df_daily.query('(year == 2019) & (incident_count > 400)')['incident_date'].dt.strftime('%A').iloc[0])\n",
    "print(df_daily.query('(year == 2022) & (incident_count > 400)')['incident_date'].dt.strftime(\"%y-%m-%d\").iloc[0], df_daily.query('(year == 2019) & (incident_count > 400)')['incident_date'].dt.strftime('%A').iloc[0])\n",
    "print(df_daily.query('(year == 2023) & (incident_count > 400)')['incident_date'].dt.strftime(\"%y-%m-%d\").iloc[0], df_daily.query('(year == 2019) & (incident_count > 400)')['incident_date'].dt.strftime('%A').iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do these days have in common? \n",
    "# They are Pride Days! It looks like there is a dramatic increase in crime reports on those days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what crime is being increased on pride spesifically.\n",
    "\n",
    "df_2019_pride = df_main[df_main['incident_date'].dt.strftime(\"%Y-%m-%d\") == '2019-06-30']['category'].value_counts().reset_index()\n",
    "df_2022_pride = df_main[df_main['incident_date'].dt.strftime(\"%Y-%m-%d\") == '2022-06-26']['category'].value_counts().reset_index()\n",
    "df_2023_pride = df_main[df_main['incident_date'].dt.strftime(\"%Y-%m-%d\") == '2023-06-25']['category'].value_counts().reset_index()\n",
    "pride_merged = pd.merge(daily_avg, df_2019_pride, on='category', how='inner')\n",
    "pride_merged = pd.merge(pride_merged,df_2022_pride, on='category', how='inner')\n",
    "pride_merged = pd.merge(pride_merged,df_2023_pride, on='category', how='inner')\n",
    "pride_merged.columns=['category', 'daily_average', 'count_2019', 'count_2022', 'count_2023']\n",
    "\n",
    "pride_merged['pride_average'] = np.mean(pride_merged[['count_2019', 'count_2022', 'count_2023']], axis=1)\n",
    "pride_merged['difference'] = pride_merged['pride_average'] - pride_merged['daily_average']\n",
    "pride_merged = pride_merged.sort_values(by='difference', ascending=False)\n",
    "pride_merged.category = pride_merged.category.astype(str)\n",
    "pride_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "prd_merged_long = pd.melt(pride_merged, id_vars='category', value_vars=['daily_average', 'pride_average'], var_name='averages', value_name='value')\n",
    "prd_merged_long.head()\n",
    "sns.barplot(x='category', y='value', data=prd_merged_long, hue='averages')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Crime Amount Comparison Pride Day vs Other Days')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On average pride days Larceny Theft shows significant increase. From 108.6 to 291 on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_merged\n",
    "del df_days\n",
    "del df_day_cat\n",
    "del df_weekday\n",
    "del df_2019_pride \n",
    "del df_2022_pride\n",
    "del df_2023_pride\n",
    "del daily_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check what are the monthly distributions of the top 5 crimes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_distribution(years=(2018, 2024), df=df_main, super_title= \"Title\"):\n",
    "    # Calculate the number of rows needed based on the year range\n",
    "    n_rows = ((years[1] - years[0]) // 3) + 1\n",
    "    plt.style.use('ggplot')\n",
    "    fig, ax = plt.subplots(n_rows, 3, figsize=(20, 5 * n_rows))\n",
    "    ax = ax.flatten() \n",
    "    \n",
    "    for i, year in enumerate(range(years[0], years[1] + 1)):\n",
    "     \n",
    "        df_year = df.loc[(df.index < pd.Timestamp(str(year + 1))) & (df.index >= pd.Timestamp(str(year)))].copy()\n",
    "        \n",
    "      \n",
    "        df_year['year_month_text'] = df_year.incident_date.dt.strftime('%Y-%m')\n",
    "        \n",
    "       \n",
    "        df_year = df_year.groupby(\"year_month_text\").size().reset_index().set_index('year_month_text').rename(columns={0: \"count\"})\n",
    "        \n",
    "     \n",
    "\n",
    "        sns.barplot(x='year_month_text', y='count', data=df_year, ax=ax[i], hue='count')\n",
    "        ax[i].set_title(f\"{year}\")\n",
    "        ax[i].tick_params(axis='x', rotation=90)\n",
    "        ax[i].legend().remove()\n",
    " \n",
    "    for j in range(i + 1, len(ax)):\n",
    "        ax[j].set_visible(False)\n",
    "    plt.suptitle(super_title, y=1)\n",
    "    plt.tight_layout()\n",
    "   \n",
    "    plt.show();\n",
    "\n",
    "# Example usage\n",
    "monthly_distribution(years=(2018, 2024), df=df_main, super_title= 'Monthly Crime Counts per Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_distribution(years=(2018, 2024), df=df_main[df_main.category == 'Larceny Theft'], super_title=\"Monthly Larceny Theft Counts per Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_distribution(years=(2018, 2024), df=df_main[df_main.category == 'Robbery'], super_title=\"Monthly Robbery Counts per Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets add `is_holiday` categorical column if date is holiday or not in US and `holiday_type` column to identfy what holiday it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_holidays = holidays.US() \n",
    "df_main['is_holiday'] = df_main.incident_date.apply(lambda x: x in (us_holidays))\n",
    "df_main['holiday_type'] = np.array([us_holidays.get(day) for day in df_main.incident_date])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_main.subcategory.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_dist(year=2022, df = df_main, cat='Theft From Vehicle'):\n",
    "    df_year = df.loc[df_main.incident_date.dt.year == year].copy()\n",
    "    \n",
    "    df_year = df_year[df_year.subcategory == cat].groupby('incident_date')['category'].size().reset_index()\n",
    "    df_year['holiday_type'] = np.array([us_holidays.get(day) for day in df_year.incident_date])\n",
    "    df_year['holiday_type'] = df_year['holiday_type'].fillna(df_year['incident_date'].apply(lambda x: \"Weekend\" if x.strftime(\"%A\") in ['Friday', 'Saturday'] else 'Weekday'))\n",
    "    plt.figure(figsize=(25,13))\n",
    "    sns.scatterplot(x='incident_date', y='category', hue=\"holiday_type\", data=df_year, palette='bright', size='holiday_type')\n",
    "    sns.lineplot(x='incident_date', y='category', data=df_year)\n",
    "    plt.axhline(np.mean(df_year['category']), label='Average', color='blue')\n",
    "    \n",
    "    plt.ylabel('count')\n",
    "    plt.title(f\"Daily {cat} incident counts for {year}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_dist(cat= 'Burglary - Residential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical line show the average crime amount for that year. My hypothesis is holidays and next couple of days have higher Residential Burglary.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean_list = [df_main[df_main['subcategory']=='Burglary - Residential'].groupby('incident_date').size().sample(100).mean() for _ in range(1000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets find out what is the average on holidays and following 3 days of holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "df_burglary =df_main[df_main['subcategory'] == 'Burglary - Residential'].groupby('incident_date').size().reset_index().rename(columns={0:'count'})\n",
    "df_burglary['is_holiday']  = df_burglary.incident_date.apply(lambda x: x in (us_holidays))\n",
    "# Lets change is holiday to true for 3 days following holiday\n",
    "i = 0\n",
    "while i < len(df_burglary) - 5:\n",
    "    if df_burglary.loc[i, 'is_holiday']:\n",
    "     \n",
    "        df_burglary.loc[i+1:i+3, 'is_holiday'] = True\n",
    "        i+=4\n",
    "    \n",
    "    else:\n",
    "        i+=1\n",
    "   \n",
    "\n",
    "sns.histplot(sample_mean_list,  stat='probability', bins=30, color='orange')\n",
    "percentiles = np.percentile(sample_mean_list, [2.5, 97.5])\n",
    "plt.axvline(x=percentiles[0], color='red', linestyle='--', label='2.5th Percentile')\n",
    "plt.axvline(x=percentiles[1], color='red', linestyle='--', label='97.5th Percentile')\n",
    "plt.axvline(x=(observed:=np.mean(df_burglary[df_burglary['is_holiday']]['count'])), c='green',label='Observed Mean on Holidays')\n",
    "plt.legend()\n",
    "plt.title('Daily Average Burglary-Residential Distribution')\n",
    "plt.xlabel('Burglary - Residential')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since the observed value in the confidence interval we can not reject the null hypothesis. To make it official lets get the p-value. (Pre-selected treshold will be 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.mean(sample_mean_list >= observed)\n",
    "print(f\"P-value: {p_value} \\nP-value is larger than 0.05\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holidays has no significant impact on residential Burglary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create a table to keep only daily constant details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eachday = df_main.loc[~df_main.duplicated(subset='incident_date', keep='first')]\n",
    "df_eachday = df_eachday[['incident_date', 'is_holiday', 'holiday_type' ,'precipitation']].reset_index(drop=True)\n",
    "df_eachday.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top5 = df_main[df_main['category'].isin(top5_cat)].astype(str)\n",
    "df_top5= df_top5.groupby('incident_date')['category'].value_counts().reset_index()\n",
    "df_top5 = df_top5.pivot_table(values='count', index= 'incident_date', columns='category').reset_index()\n",
    "df_top5['incident_date'] = pd.to_datetime(df_top5['incident_date'], format=\"%Y-%m-%d\")\n",
    "df_top5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_merged = df_eachday.merge(df_top5, on='incident_date', how='left')\n",
    "df_day_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='precipitation', y='Larceny Theft', data=df_day_merged[df_day_merged['precipitation'] <=2], hue='Larceny Theft')\n",
    "plt.title('Impact of Precipitation on Larceny Theft Incidents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "top5_sub = df_main.subcategory.value_counts()[:5].reset_index()['subcategory'].tolist()\n",
    "df_top5 = df_main[df_main['subcategory'].isin(top5_sub)].astype(str)\n",
    "df_top5= df_top5.groupby('incident_date')['subcategory'].value_counts().reset_index()\n",
    "df_top5 = df_top5.pivot_table(values='count', index= 'incident_date', columns='subcategory').reset_index()\n",
    "df_top5['incident_date'] = pd.to_datetime(df_top5['incident_date'], format=\"%Y-%m-%d\")\n",
    "df_top5.head()\n",
    "df_day_merged = df_eachday.merge(df_top5, on='incident_date', how='left')\n",
    "df_day_merged.head()\n",
    "for sub in top5_sub:\n",
    "    plt.scatter(df_day_merged['precipitation'], df_day_merged[sub], alpha=0.7, label=sub)\n",
    "    plt.title(f'Impact of Precipitation on {sub}')\n",
    "plt.xlabel(\"Rain Level\")\n",
    "plt.ylabel(\"Incident Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My hypothesis is that rain and Larceny - From Vehicle have a negative correlation. This is not clearly visible in the plot. To check if this relationship is statistically significant, I will perform a hypothesis test. Let's start by comparing the mean number of reported incidents on rainy versus non-rainy days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_no_rain = np.mean(df_day_merged.query('precipitation < 0.3')['Larceny - From Vehicle'])\n",
    "mean_rain = np.mean(df_day_merged.query('precipitation >= 0.3')['Larceny - From Vehicle'])\n",
    "print('Average Larceny from vehicle on a sunny day is', mean_no_rain)\n",
    "print('Average Larceny from vehicle on a rainy day is', mean_rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That difference beween sunny day and rainy day looks so little, looks like rain does not stop people from going out and stealing from cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check if there is a location pattern for certain types of crime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  neighborhood_crime_bar(data = df_main, year=None, category='Larceny - From Vehicle'):\n",
    "    df_ = data.groupby(['incident_date', 'neighborhood'])['subcategory'].value_counts().reset_index()\n",
    "    df_['subcategory'] = df_['subcategory'].astype(str)\n",
    "    df_sub = df_[df_['subcategory'] == category]\n",
    "    df_sub_neig = df_sub.groupby('neighborhood')['count'].sum().reset_index().sort_values(by='count', ascending=False)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.barplot(x=df_sub_neig['neighborhood'], y=df_sub_neig['count'], hue=df_sub_neig['neighborhood'])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'{category} Count for Neighborhoods')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_crime_bar(category='Burglary - Residential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_crime_bar(category='Larceny Theft - Pickpocket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a function to calculate and visualize the ratio of a specific crime category in different neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crime_ratio_by_neighborhood(category='Prostitution'):\n",
    "    neighborhood_list = []\n",
    "    ratio_list = []\n",
    "    for neighborhood in df_main['neighborhood'].unique():\n",
    "        a_crime = len(df_main[(df_main['subcategory'] == category) & (df_main['neighborhood'] == neighborhood)])\n",
    "\n",
    "        total_crime = sum(df_main['neighborhood'] == neighborhood)\n",
    "        ratio = a_crime / total_crime\n",
    "        neighborhood_list.append(neighborhood)\n",
    "        ratio_list.append(ratio)\n",
    "        \n",
    "    zipped = list(zip(neighborhood_list, ratio_list))\n",
    "    zipped=sorted(zipped, key=(lambda x: x[1]), reverse=True)\n",
    "    neighborhood_list = [tpl[0] for tpl in zipped]\n",
    "    ratio_list = [tpl[1] for tpl in zipped]\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.barplot(x=neighborhood_list, y=ratio_list, hue=ratio_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"{category} ratio for Neighborhoods\")\n",
    "    plt.xlabel('Neighborhood')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_ratio_by_neighborhood(category='Burglary - Residential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read the plot above?  \n",
    "### The crime category 'Burglary - Residential' comprises around 8.5% of all crimes in Noe Valley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Find out most popular crimes for each neighborhood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "df_neighborhood = df_main.groupby('neighborhood')['subcategory'].value_counts().reset_index()\n",
    "df_neighborhood = df_neighborhood.loc[~df_neighborhood.duplicated(subset='neighborhood', keep='first')]\n",
    "df_neighborhood['subcategory'] = df_neighborhood['subcategory'].astype(str)\n",
    "sns.barplot(x='neighborhood', y='count', hue='subcategory' , data=df_neighborhood)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Most Common Crimes for Neighborhoods\")\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like Larceny - From Vehicle is number one crime almost all over the city. What crime would be appear if we filter 'Larceny - From Vehicle'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "df_neighborhood = df_main[df_main['subcategory'] != 'Larceny - From Vehicle'].groupby('neighborhood')['subcategory'].value_counts().reset_index()\n",
    "df_neighborhood = df_neighborhood.loc[~df_neighborhood.duplicated(subset='neighborhood', keep='first')]\n",
    "df_neighborhood['subcategory'] = df_neighborhood['subcategory'].astype(str)\n",
    "sns.barplot(x='neighborhood', y='count', hue='subcategory' , data=df_neighborhood)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Most Common Crimes for Neighborhoods (Larceny - From Vehicle filtered)\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_main[df_main['subcategory'] == 'Larceny - From Vehicle']\n",
    "day = pd.Timestamp('2018-01-01')\n",
    "#df_sub_date = df_sub.query(\"incident_date == @day\")\n",
    "background_image = mpimg.imread('./SanFranciscoNeighborhoods.jpg')\n",
    "\n",
    "\n",
    "def plot_map(day):\n",
    "    \n",
    "    df_sub_date = df_sub[df_sub['incident_date'] == pd.Timestamp(day)]\n",
    "    df_sub_date = df_sub_date.sort_values(by='incident_time')\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    # Display the background image\n",
    "    plt.imshow(background_image, extent=[-122.52, -122.35, 37.68, 37.83], aspect='auto')\n",
    "    palette = sns.color_palette(palette='OrRd')\n",
    "    # Plot the scatterplot on top of the background\n",
    "    sns.scatterplot(y='latitude', x='longitude', data=df_sub_date, s=100, alpha=0.8, hue=df_sub_date.index.hour, palette='OrRd')\n",
    "    # Adjust axes limits to match the map\n",
    "    plt.xlim([-122.52, -122.35])\n",
    "    plt.ylim([37.68, 37.83])\n",
    "    plt.title('Larceny - From Vehicle on Map')\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "start_day = pd.Timestamp('2018-01-01')\n",
    "end_day = pd.Timestamp('2024-05-01') \n",
    "\n",
    "day_slider = widgets.DatePicker(\n",
    "    description='Select Date',\n",
    "    value=start_day,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Display the interactive plot\n",
    "interact(plot_map, day=day_slider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lest find out the center (mean) for certain crime where it locates in the City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_center_for_crime(ax,crime_sub=\"Larceny Theft - From Building\"):\n",
    "    mean_latitude, mean_longitude = df_main[df_main['category'] == crime_sub ][['latitude', 'longitude']].agg(np.mean)\n",
    "    #plt.imshow(background_image, extent=[-122.52, -122.35, 37.68, 37.83], aspect='auto')\n",
    "    ax.scatter([mean_longitude],[mean_latitude], marker='o',alpha=1, label=crime_sub, s=100, edgecolors='white',linewidth=3)\n",
    "    #plt.show()\n",
    "#plot_weight_center_for_crime()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.imshow(background_image, extent=[-122.52, -122.35, 37.68, 37.83], aspect='auto')\n",
    "for cat in top5_cat:\n",
    "    plot_weight_center_for_crime(ax, cat)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"The center of Top 5 crimes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_on_map_with_subcategory(cat_type):\n",
    "    sf_map= folium.Map(location=[37.7749, -122.4194], zoom_start=12)\n",
    "\n",
    "    marker_cluster = MarkerCluster().add_to(sf_map)\n",
    "    \n",
    "    for i, row in df_main.loc[df_main['subcategory']==cat_type].iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=row['incident_date'].strftime('%B %d,%Y')\n",
    "        ).add_to(marker_cluster)\n",
    "    return(sf_map)\n",
    "    \n",
    "sf_map =find_on_map_with_subcategory('Larceny - From Vehicle')\n",
    "sf_map.save('larceny_from_vehicle_on_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sf_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize the hourly distribution of crimes to identify any potential clusters at specific times of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.info()\n",
    "df_main['incident_hour'] = df_main['incident_time'].apply(lambda x: int(x[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "sns.histplot(x='incident_hour', data=df_main, hue='category', multiple='stack', bins=24)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Hourly Distribution of Crime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create a function to visualize same graphic for certain crime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_by_time(cat='Assault'):\n",
    "    df_cat = df_main.loc[df_main['category'] == cat].copy()\n",
    "    df_cat['subcategory'] = df_cat['subcategory'].astype(str)\n",
    "    plt.figure(figsize=(25,10))\n",
    "    sns.histplot(x='incident_hour', data=df_cat, hue='subcategory', multiple='stack', bins=24)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Hourly Distribution of {cat}')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_by_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_by_time('Larceny Theft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,8))\n",
    "sns.boxplot(x='category', y='incident_hour', data=df_main)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Hourly Distribution of each Crime Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,8))\n",
    "sns.boxplot(x='subcategory', y='incident_hour', data=df_main, hue='subcategory')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Hourly Distribution of each Crime Subcategory\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see the correlation between max and min temperature if wee need to keep both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.regplot(x='min_temperature', y='max_temperature', data=df_main)\n",
    "average_temp = (df_main['min_temperature'] + df_main['max_temperature'])/2\n",
    "plt.scatter(average_temp, average_temp, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_coefficient, p_value= pearsonr(df_main['min_temperature'], df_main['max_temperature'])\n",
    "correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['avg_temp'] = average_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets eliminate the columns will no need any further \n",
    "df_main = df_main[['incident_date', 'incident_time', 'incident_day', 'category', 'subcategory', 'latitude', 'longitude', 'avg_temp', 'precipitation', 'is_holiday', 'holiday_type']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
